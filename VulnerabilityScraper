from bs4 import BeautifulSoup
import requests
import csv
from datetime import date
def main():
    dat=soupy()
    scraper_py(dat)
def soupy ():
    url="https://www.cisa.gov/known-exploited-vulnerabilities-catalog"
    result= requests.get(url)
    doc=BeautifulSoup(result.text, "html.parser")
    tbody=doc.tbody
    trs = tbody.contents
    CVE_list = []
    for tr in trs:
        CVE_tag = tr.contents[:1]
        Product_tag = tr.contents[4:5]
        Vulnerability_Name_tag = tr.contents[6:7] 
        Date_Added_tag = tr.contents[8:9]
        for line in Date_Added_tag:
            Date_Added = line.text            
        for line in CVE_tag:
            CVE = line.text            
        for line in Product_tag:
            Product = line.text            
        for line in Vulnerability_Name_tag:
            Vulnerability = line.text            
        link=[tag.find("a")["href"] for tag in tr.select("td:has(a)")]   
        CVE_list.append([Date_Added, CVE, Product, Vulnerability, link[0]])        
    with open('Cisa_CVEs', 'w', newline='') as file:
        writer = csv.writer(file)
        headers = ["Date-Added", "CVE", "Product/Vendor","Vulnerability Name", "link"]
        writer.writerows(headers)
        for data in CVE_list:
            writer.writerow(data)
    return data
def scraper_py (data):
    idea=True
    List_today =[]
    with open("Cisa_CVEs", 'r') as file:
        date_today =date.today()
        csv_reader=csv.reader(file)
        for line in csv_reader:
            if line[0]==date_today:
                List_today.append(line)
                idea =False
    if idea==True:
        print("Nothing new today. Have a good day!")
    with open('Current_CVE', 'w', newline='') as file:
        writer=csv.writer(file)
        headers=["Date-Added", "CVE", "Product/Vendor","Vulnerability Name", "link"]
        writer.writerow(headers)
        for data in List_today:
            writer.writerow(data)
main()

def main():
    lin=panda_creator()
    opening_panda(lin)
def panda_creator():    
    import csv
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    import pandas as pd
    file = open("Current_CVE")
    csvreader=csv.reader(file)
    header=next(csvreader)
    rows=[]
    for row in csvreader:
        rows.append(row[4])
    df=pd.read_csv("Current_CVE")
    urls = df['link']
    return urls
def opening_panda(urls): 
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.support.ui import WebDriverWait
    for lines in urls:
        print(lines)
        driver=webdriver.Firefox(executable_path = '/home/kali/geckodriver')
        driver.get(lines)
        rows=WebDriverWait(driver, 20).until(EC.visibility_of_all_elements_located((By.XPATH, "//*[@id='vulnCvssPanel']")))
main()
